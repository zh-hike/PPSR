Global:
  checkoutpoints: null
  pretrained_model: null
  output_dir: ./output/sr/X4/
  save_interval: -1
  dist: true
  save_interval: -1
  eval_during_train: true
  eval_interval: 1
  epochs: 500
  print_batch_step: 25
  bar_disable: true
  img_size: [3, 512, 512]
  schedule_update_by: epoch
  rgb_range: &rgb_range 255.0
  trainer: common
  scale: &scale 4

Arch:
  name: EDSR
  use_sync_bn: true
  n_resblocks: 16
  n_feats: 64
  n_colors: 3
  res_scale: 1.0
  scale: *scale
  rgb_range: *rgb_range

Data:
  Train:
    Dataset:
      name: DIV2K
      data_root: /mnt/zh/dataset/div2k/DIV2K
      index_file: /mnt/zh/dataset/div2k/DIV2K/bicubic_train_x2.txt
      data_expand: 20
      ops:
        - RandomCrop:
            size: 96
            pad_if_needed: true
            padding_mode: reflect
            target_scale: *scale
        - ToTensor:
            data_format: CHW
            rgb_range: *rgb_range
    
    DataLoader:
      num_workers: 12
      use_shared_memory: true
      prefetch_factor: 32
      batch_sampler:
        name: DistributedBatchSampler
        batch_size: 32
        shuffle: false
        drop_last: false
        

  Eval:
    Dataset:
      name: ValDataset
      data_root: /mnt/zh/dataset/div2k/DIV2K
      index_file: /mnt/zh/dataset/div2k/DIV2K/bicubic_val_x2.txt

    DataLoader:
      num_workers: 12
      use_shared_memory: true
      prefetch_factor: 2
      batch_sampler:
        name: DistributedBatchSampler
        batch_size: 1
        shuffle: false

  Test:
    path: /mnt/zh/dataset/div2k/DIV2K/DIV2K_valid_LR_bicubic/X2

Loss:
  Train:
    - L1Loss:
        weight: 1
  
  Eval:
    - L1Loss:
        weight: 1

Optimizer:
  name: Adam
  beta1: 0.9
  beta2: 0.999
  grad_clip: 0.
  learning_rate:
    name: MultiStepDecay
    milestones: [50]
    gamma: 0.5
    learning_rate: 0.0004

Metric:
  save_rely_metric: PSNR
  Eval:
    - PSNR:
        weight: 1
        data_range: *rgb_range
    - SSIM:
        weight: 1
        data_range: *rgb_range
