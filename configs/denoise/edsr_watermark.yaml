Global:
  checkoutpoints: null
  pretrained_model: null
  output_dir: ./output/denoise/
  save_interval: -1
  dist: true
  save_interval: -1
  eval_during_train: true
  eval_interval: 1
  epochs: 500
  step_per_epoch: 200
  print_batch_step: 25
  bar_disable: true
  img_size: [3, 128, 128]
  schedule_update_by: epoch
  rgb_range: &rgb_range 255.0
  trainer: common
  scale: &scale 1

Arch:
  name: EDSR
  use_sync_bn: true
  n_resblocks: 16
  n_feats: 64
  n_colors: 3
  res_scale: 1.0
  scale: *scale
  rgb_range: *rgb_range

Data:
  Train:
    Dataset:
      name: WaterMark
      data_root: ../dataset/watermark/data/train
      index_file: ../dataset/watermark/data/train/train_index.txt
      ops:
        - RandomCrop:
            size: 96
            pad_if_needed: true
            padding_mode: reflect
            target_scale: *scale
        - ToTensor:
            data_format: CHW
            rgb_range: *rgb_range
    
    DataLoader:
      num_workers: 8
      use_shared_memory: true
      prefetch_factor: 32
      batch_sampler:
        name: DistributedBatchSampler
        batch_size: 32
        shuffle: false
        drop_last: false
        
  Eval:
    Dataset:
      name: ValDataset
      data_root: ../dataset/watermark/data/train
      index_file: ../dataset/watermark/data/train/val_index.txt

    DataLoader:
      num_workers: 8
      use_shared_memory: true
      prefetch_factor: 2
      batch_sampler:
        name: DistributedBatchSampler
        batch_size: 1
        shuffle: false

  Test:
    path: ../dataset/watermark/data/test_make_A

Loss:
  Train:
    - L1Loss:
        weight: 1
  
  Eval:
    - L1Loss:
        weight: 1

Optimizer:
  name: Adam
  beta1: 0.9
  beta2: 0.999
  grad_clip: 0.
  learning_rate:
    name: MultiStepDecay
    milestones: [5, 10, 20]
    gamma: 0.5
    learning_rate: 0.0004

Metric:
  save_rely_metric: Score
  Eval:
    - Score:
        PSNR:
          weight: 0.005
          data_range: *rgb_range
        MSSSIM:
          weight: 0.5
          data_range: *rgb_range